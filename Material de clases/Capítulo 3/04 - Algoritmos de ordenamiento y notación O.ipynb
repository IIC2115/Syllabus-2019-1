{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <font size='5' face='Georgia, Arial'>IIC2115 - Programación como herramienta para la ingeniería</font><br>\n",
    "    <font size='1'>Basado en el material descrito en http://brilliant.org.</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de ordenamiento y notación O\n",
    "Un algoritmo de ordenamiento es un algoritmo que toma un arreglo (lista) como entrada, lleva a cabo las operaciones especificadas en él, y entrega como salida un arreglo ordenado, en base a cierto criterio previamente especificado. Los algoritmos de ordenamiento brindan una manera directa de introducir la notación $\\mathcal{O}$, un tema clave en el estudio de la complejidad de algoritmos. Este herramienta que nos ayudará a identificar los factores clave a considerar al diseñar un algoritmo, y en particular, a elegir un algoritmo de ordenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de algoritmo de ordenamiento\n",
    "Hay dos tipos de algoritmos de ordenamiento: en base a comparaciones y en base a enteros. Los basados en comparaciones, comparan elementos en cada paso del algoritmo, para determinar si un elemento debe estar a la izquierda o a la derecha de otro elemento. \n",
    "\n",
    "Los algoritmos de ordenamiento basados en enteros determinan para cada elemento $x$ cuántos elementos son menores que $x$. Si hay $14$ elementos que son menos de $x$, entonces $x$ se colocarán en el puesto $15$. Esta información se usa para colocar cada elemento en su posición correcta de inmediato, sin necesidad de reorganizar las listas.\n",
    "\n",
    "Los algoritmos de ordenamiento basados en comparación suelen ser más sencillos de implementar que los basados en enteros, pero generalmente están limitados por una cota inferior de tiempo de ejecución que es más alta que el de los de ordenamiento de enteros. Esto significa que, en promedio, los algoritmos basados en comparación no pueden ser más rápidos que los basados en enteros. Por otro lado, los algoritmos basados en enteros no hacen comparaciones, por lo que no tienen el mismo límite inferior que los ordenamientos de comparación.\n",
    "\n",
    "Un límite inferior para un algoritmo es el peor tiempo de ejecución del mejor algoritmo posible para un problema determinado. La parte \"en promedio\" aquí es importante: hay muchos algoritmos que se ejecutan en tiempo muy rápido si la lista ingresada ya está ordenada, o  sitiene alguna propiedad muy particular (y poco probable en general). Solo hay una permutación de una lista ordenada, pero $n!$ listas posibles, por lo que las posibilidades de que la entrada ya esté ordenada son muy bajas, y en promedio, la lista no lo estará."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notación O\n",
    "La notación $\\mathcal{O}$ es una notación utilizada cuando se habla de tasas de crecimiento. Formaliza la noción de que dos funciones \"crecen a la misma velocidad\", o una función \"crece más rápido que la otra\".\n",
    "\n",
    "La notación $\\mathcal{O}$ se usa muy comúnmente cuando se analizan algoritmos. Los algoritmos tienen un tiempo de ejecución específico, generalmente dado por una función de su tamaño de entrada. Sin embargo, las implementaciones de un determinado algoritmo en diferentes lenguajes pueden producir una función diferente. Por ejemplo, un algoritmo con tamaño de entrada de $n$ enteros, cuando se implementa en un lenguaje, puede llevar un tiempo de $n^2 $ microsegundos, pero cuando se implementa en otro, podría tomar un tiempo $1000n^2 + 1000n$ microsegundos debido a que es un lenguaje más lento. Por lo tanto, a menudo hablamos de la tasa de crecimiento de un algoritmo, si el algoritmo solo toma tiempo proporcional a su tamaño de entrada (lineal), o el cuadrado del tamaño (cuadrático), o tal vez no depende de su tamaño de entrada (constante). Esto se formaliza en la notación $\\mathcal{O}$, indicando que el algoritmo anterior se ejecuta en \"tiempo cuadrático\" o \"$\\mathcal{O} (n^2)$\".\n",
    "\n",
    "### Intuición detrás de la notación O\n",
    "Informalmente, si tenemos funciones $f,g$, tales que $f$ eventualmente crecerá más lento que un múltiplo de $g$, decimos $f=\\mathcal{O}(g)$. Por ejemplo, consideremos las funciones $f(n)=1000n^2$ y $g(n)=n^3$, a medida que $n\\rightarrow\\infty$. Eventualmente, concretamente cuando $n>1000$, vemos que $f(n)<g(n)$, y por lo tanto $f(n)$ crece más lento que $g(n)$. Esto significa $f=\\mathcal{O}(g)$, o $1000n^2=\\mathcal{O}(n^3)$. De hecho, como se indica que _algún múltiplo de $g$_, también tenemos $1000n^2=\\mathcal{O}(n^2)$.\n",
    "\n",
    "### Definición formal\n",
    "\n",
    "Formalizamos la definición anterior, principalmente aclarando qué significa _eventualmente_ y _más lento_:\n",
    "\n",
    "> Si $f(x),g(x)$ son funciones en los números reales, entonces decimos $f=\\mathcal{O}(g)$, o $f$ es __o de__ $g$ a medida que $x\\rightarrow\\infty$, si existen constantes $M,c$, tales que $\\lvert f(x)\\rvert\\leq c\\lvert g(x)\\rvert,\\forall x>m$.\n",
    "\n",
    "### Análisis de algoritmos\n",
    "Para el análisis de algoritmos, el aspecto más importante a analizar es cómo se comportan los algoritmos con diferentes tamaños de entrada. Un algoritmo puede tomar un tiempo proporcional a su tamaño de entrada, por lo tanto, doblar el tamaño de entrada hace que se ejecute el doble de tiempo. O tal vez es proporcional a su tamaño de entrada al cuadrado, por lo que duplicar el tamaño de entrada hace que se su ejecución tome cuatro veces más tiempo.\n",
    "\n",
    "Para ignorar las diferencias en la implementación (diferentes lenguajes o computadores), a menudo recurrimos a la __tasa de crecimiento asintótico__ de una función. Dado un consumo de recursos de $f$ (el algoritmo), buscamos una función simple $g$ tal que $f=\\mathcal{O}(g)$. Las diferentes implementaciones ahora están ocultas en en $\\mathcal{O}$, y el foco está ahora en $g$, si toma tiempo lineal ($g(n)=n$), o cuadrático ($g(n)=n^2$), o algún otro valor. El comportamiento en diferentes tamaños de entrada todavía se conserva aquí; doblar el valor de entrada dará como resultado el mismo comportamiento en $g$. Por lo tanto, desde el punto de vista del análisis de los algoritmos, no perdemos ninguna información por simplificar $f$ en $g$, ya que ambas tienen el mismo comportamiento. Esto nos permite comparar diferentes algoritmos de acuerdo con sus tasas de crecimiento y afirmar que un algoritmo es \"más rápido\" que otro: si tenemos dos algoritmos con un consumo de recursos $f_1, f_2$ respectivamente, y tenemos $f_1=\\mathcal{O}(g_1), f_2=\\mathcal{O}(g_2) $, luego decimos que el primer algoritmo es más rápido que el segundo si $g_1=\\mathcal{O}(g_2)$.\n",
    "\n",
    "### Algunas tasas de crecimiento de algoritmos comunes\n",
    "Al analizar el tiempo de ejecución de un algoritmo, existen muchas tasas de crecimiento comunes para las que tenemos nombres específicos. Estas son algunas de ellos, desde las más lentas hasta las más rápidas. En todas estas, $n$ aumenta sin límite ($n\\rightarrow\\infty$). Este suele ser el tamaño de entrada, pero a veces cuando la entrada es un número natural, tomamos $n$ como el valor de este número, o cuando la entrada es una lista de elementos, $n$ es la cantidad de elementos sin considerar cuán grandes son los elementos individuales.\n",
    "\n",
    "* $\\mathcal{O}(1) $: los algoritmos de tiempo constante se ejecutan en un tiempo constante sin importar cuán grande sea la entrada. Por ejemplo, verificar si el primer carácter de un archivo es _a_, es un tiempo constante; no importa cuán grande sea el archivo, solo necesitamos inspeccionar el primer byte.\n",
    "* $\\mathcal{O}(\\log n)$: los algoritmos de tiempo logarítmico se ejecutan en un tiempo proporcional al logaritmo de la entrada. El ejemplo más común es quizás la búsqueda binaria: dado un arreglo ordenado de $n$ elementos, podemos encontrar si un elemento específico está en él mediante la búsqueda binaria, dividiendo el espacio de búsqueda por la mitad mediante la comprobación del elemento medio.\n",
    "* $\\mathcal{O}(n)$: los algoritmos de tiempo lineal se ejecutan en tiempo proporcional a la entrada. Es la mejor complejidad de tiempo posible en situaciones donde el algoritmo tiene que leer secuencialmente toda su entrada. Por ejemplo, calcular el cuadrado de cada elemento de un vector se puede hacer en tiempo lineal, lo que es un rendimiento muy bueno (suponiendo que la multiplicación sea $\\mathcal{O}(1)$).\n",
    "* $\\mathcal{O}(n\\log n) $: los algoritmos de tiempo linearítmico se ejecutan en un tiempo que no es particularmente distinguible del tiempo lineal, para una entrada \"razonable\". Este nivel de complejidad es todavía considerado muy bueno.\n",
    "* $\\mathcal{O}(n^2)$: los algoritmos de tiempo cuadrático toman tiempo proporcional al cuadrado de la entrada. Un ejemplo de algoritmos que toman este tiempo son la suma y la resta de una matriz cuadrada de lado $n$.\n",
    "* $\\mathcal{O}(n^3)$: los algoritmos de tiempo cúbico más comunes son quizás los de multiplicación de matrices estándar. Aparte de estos, un algoritmo de tiempo cúbico probablemente tendrá la estructura de un ciclo a través de $n$ valores dentro de otro ciclo de $n$ valores dentro de un tercer ciclo de $n$ valores.\n",
    "* $\\mathcal{O}(n^k)$: Estos algoritmos toman una serie de pasos que están delimitados por un polinomio cuyo elemento mayor es de orden $k$, para un entero no negativo $k$, donde $n$ es el tamaño de la entrada. Se dice que los algoritmos de tiempo polinomial son _rápidos_ y, como tales, son extremadamente importantes en ciencia de la computación. El cálculo de raíces cuadradas, potencias y logaritmos se puede realizar en tiempo polinomial.\n",
    "* $\\mathcal{O}(a^n)$: Para un algoritmo de tiempo exponencial, aumentar la entrada en uno es suficiente para multiplicar el tiempo de ejecución del algoritmo en $a$. Un ejemplo de esto es evaluar si se puede satisfacer (si es verdadera) una fórmula booleana de $n$ variables; intentar cada posibilidad requiere que se verifiquen $2^n$ casos (multiplicado por el tiempo que lleva evaluar realmente la fórmula). Los algoritmos exponenciales se consideran _lentos_, ya que son generalmente inmanejables cuando crece el tamaño de la entrada.\n",
    "* $\\mathcal{O}(n!)$: un algoritmo de tiempo factorial es incluso más lento que uno exponencial. Tales algoritmos a menudo verifican cada permutación de un arreglo de tamaño $n$, lo que implica al menos $n!$ pasos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedades de los algoritmos de ordenamiento\n",
    "\n",
    "### Complejidad de ejecución\n",
    "Todos los algoritmos de ordenamiento comparten el objetivo de generar una lista ordenada, pero la forma en que cada algoritmo realiza esta tarea puede variar. Así, al trabajar con cualquier tipo de algoritmo, es importante saber qué tan rápido se ejecuta, en otras palabras, su complejidad de tiempo.\n",
    "\n",
    "Los algoritmos de ordenamiento basados en la comparación tienen una complejidad de tiempo de ejecución de $\\mathcal{O}(n\\log n)$, mientras que los algoritmos de ordenamiento basados en enteros tienen una complejidad de $\\mathcal{O}(n)$. Vale la pena señalar que si un algoritmo tiene un peor tiempo de ejecución de $\\mathcal {O}(n\\log n)$, entonces se garantiza que el algoritmo nunca será más lento que $\\mathcal{O}(n\\log n)$, y si un algoritmo tiene un tiempo promedio de ejecución de $\\mathcal{O}(n^2) $, entonces, en promedio, no será más lento que $\\mathcal{O}(n^2)$ (pero puede ser más lento o más rápido que eso para ciertas entradas).\n",
    "\n",
    "### Estabilidad\n",
    "Un algoritmo de ordenamiento es estable si conserva el orden original de los elementos que tienen el mismo valor para la clave (donde la clave es el valor que ordena el algoritmo). Por ejemplo:\n",
    "\n",
    "<img src=\"figs/stability.png\" style=\"width: 300px;\"/>\n",
    "\n",
    "Cuando las cartas se ordenan por su valor con un ordenamiento estable, las dos cartas 5 deben permanecer en el mismo orden en el que estaban originalmente, en la salida ordenada . Cuando se organizan con un ordenamiento no estable, las cartas 5 pueden terminar en el orden opuesto en la salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algunos algoritmos de ordenamiento comunes\n",
    "\n",
    "### Insertion Sort\n",
    "Insertion sort es un algoritmo estable basado en comparación, con una complejidad de ejecución promedio de $\\mathcal{O}(n^2)$. Construye un arreglo ordenado final un elemento a la vez, iterando a través de un arreglo de entrada y eliminando un elemento por iteración. Este elemento elimiando es reubicado en el lugar al que pertenece de acuerdo al orden, desplazando al resto de los elementos hacia la derecha.\n",
    "![](figs/insertion_sort.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(array):\n",
    "    for slot in range(1, len(array)): \n",
    "        value = array[slot]\n",
    "        test_slot = slot - 1\n",
    "        while test_slot > -1 and array[test_slot] > value:\n",
    "            array[test_slot + 1] = array[test_slot]\n",
    "            test_slot = test_slot - 1\n",
    "        array[test_slot + 1] = value\n",
    "    return array\n",
    "\n",
    "array = [9,3,1,4,5,7,7,2,2]\n",
    "print(\"Original: \" + str(array))\n",
    "print(\"Sorted:   \" + str(insertion_sort(array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bubble sort\n",
    "Bubble sort es un algoritmo estable basado en comparación, con una complejidad de ejecución promedio de $\\mathcal{O}(n^2)$. Compara cada par de elementos en un arreglo y los intercambia si están fuera de orden, hasta que se ordena el arreglo completo. Para cada elemento en el arreglo, el algoritmo lo compara con cada uno de los otros elementos.\n",
    "![](figs/bubble_sort.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bubble_sort(array):\n",
    "    index = len(array) - 1\n",
    "    while index >= 0:\n",
    "        for j in range(index):\n",
    "            if array[j] > array[j+1]:\n",
    "                array[j], array[j+1] = array[j+1], array[j]\n",
    "        index -= 1\n",
    "    return array\n",
    "\n",
    "array = [9,3,1,4,5,7,7,2,2]\n",
    "print(\"Original: \" + str(array))\n",
    "print(\"Sorted:   \" + str(bubble_sort(array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge sort\n",
    "Merge sort es un algoritmo estable basado en comparación, con una complejidad de ejecución promedio de $\\mathcal{O}(n\\log n)$. Se centra en cómo fusionar dos arreglos ordenados previamente, de modo que el arreglo resultante también este ordenado. También es un ejemplo de un algoritmo de dividir y conquistar.\n",
    "![](figs/merge_sort.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(left, right):\n",
    "    result = []\n",
    "    left_idx, right_idx = 0, 0\n",
    "    while left_idx < len(left) and right_idx < len(right):\n",
    "        if left[left_idx] <= right[right_idx]:\n",
    "            result.append(left[left_idx])\n",
    "            left_idx += 1\n",
    "        else:\n",
    "            result.append(right[right_idx])\n",
    "            right_idx += 1\n",
    "\n",
    "    if left:\n",
    "        result.extend(left[left_idx:])\n",
    "    if right:\n",
    "        result.extend(right[right_idx:])\n",
    "    return result\n",
    "\n",
    "def merge_sort(m):\n",
    "    if len(m) <= 1:\n",
    "        return m\n",
    "\n",
    "    middle = len(m) // 2\n",
    "    left = m[:middle]\n",
    "    right = m[middle:]\n",
    "\n",
    "    left = merge_sort(left)\n",
    "    right = merge_sort(right)\n",
    "    return list(merge(left, right))\n",
    "\n",
    "array = [9,3,1,4,5,7,7,2,2]\n",
    "print(\"Original: \" + str(array))\n",
    "print(\"Sorted:   \" + str(merge_sort(array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quicksort\n",
    "Quicksort es un algoritmo inestable basado en comparación, con una complejidad de ejecución promedio de $\\mathcal{O}(n\\log n) $. Utiliza divide y conquistar para ordenar un arreglo $A$, seleccionando un elemento pivote, $A[q]$, y luego reorganiza el arreglo en dos, $A[p \\dots q-1]$ con todos los elementos que son menores que $A[q]$ y $A[q + 1\\dots r]$, con todos los elementos siendo mayor o igual que $ A[q]$.\n",
    "![](figs/quicksort.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quicksort(arr):\n",
    "    less = []\n",
    "    pivotList = []\n",
    "    more = []\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    else:\n",
    "        pivot = arr[0]\n",
    "        for i in arr:\n",
    "            if i < pivot:\n",
    "                less.append(i)\n",
    "            elif i > pivot:\n",
    "                more.append(i)\n",
    "            else:\n",
    "                pivotList.append(i)\n",
    "        less = quicksort(less)\n",
    "        more = quicksort(more)\n",
    "        return less + pivotList + more\n",
    "\n",
    "array = [9,3,1,4,5,7,7,2,2]\n",
    "print(\"Original: \" + str(array))\n",
    "print(\"Sorted:   \" + str(quicksort(array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting sort\n",
    "Counting sort es un algoritmo de ordenamiento estabñe basado en enteros, con una complejidad promedio de $\\mathcal{O}(n + k)$. Supone que cada uno de los $n$ elementos de el arreglo de entrada, tiene un valor de clave que oscila entre $0$ y $k$, para un entero $k$. Para cada elemento en la lista, ounting sort determina la cantidad de elementos que son menores que la clave de este. COunting sort usa esta información para colocar el elemento directamente en la posición correcta del arreglo de salida.\n",
    "![](figs/counting_sort.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_sort(array, maxval):\n",
    "    n = len(array)\n",
    "    m = maxval + 1\n",
    "    count = [0] * m               \n",
    "    for a in array:\n",
    "        count[a] += 1            \n",
    "    i = 0\n",
    "    for a in range(m):            \n",
    "        for c in range(count[a]):\n",
    "            array[i] = a\n",
    "            i += 1\n",
    "    return array\n",
    "\n",
    "array = [9,3,1,4,5,7,7,2,2]\n",
    "print(\"Original: \" + str(array))\n",
    "print(\"Sorted:   \" + str(counting_sort(array,100)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
